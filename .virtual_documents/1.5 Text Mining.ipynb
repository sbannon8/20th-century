


from textblob import TextBlob
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords 
import re
nltk.download('stopwords')
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()
import os





# import text file
with open('20th_century_wiki.txt', 'r', errors='ignore') as file: 
   data = file.read().replace( '\n', ' ')


# import countries text file
path = 'C:/Users/steve/20th-century'
countries_df = pd.read_csv(os.path.join(path, 'countries_list_20th_century.csv'))








# sentence tokenization
from nltk.tokenize import sent_tokenize
tokenized_sent = sent_tokenize(data)
print(tokenized_sent)


# word tokenization
from nltk.tokenize import word_tokenize
tokenized_word = word_tokenize(data)
print(tokenized_word)





# word frequency distribution
from nltk.probability import FreqDist
dist_words = FreqDist(tokenized_word)
print(dist_words)


# show top 10 most common words
common_words = dist_words.most_common(10)
common_words


words, frequencies = zip(*common_words)
plt.figure(figsize=(8, 3))
plt.bar(words, frequencies)
plt.title('Top 10 Most Common Words')
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()





nltk.download('stopwords')


stop_words = set(stopwords.words('english'))


# removing stopwords
filtered_words = []
for word in tokenized_word:
      if word not in stop_words:
           filtered_words.append(word)


# create new FreqDist for filtered words
dist_words_filter = FreqDist(filtered_words)
print(dist_words_filter)


# show top 10 most common filtered words
common_filter_words = dist_words_filter.most_common(10)
common_filter_words


# remove common punctuation marks so not included in count
# substitue all punction marks with a space
sans_punc = re.sub("[^a-zA-Z]", #search for all non-letters
                   " ", #replace them with a space
                   str(filtered_words))


# create another tokenized object so the FreqDist function doesn't only provide you with single letters
tokenized_word_2 = word_tokenize(sans_punc)
print(tokenized_word_2)


# create new FreqDist
dist_words_filter_2 = FreqDist(tokenized_word_2)


# list common words
common_words_filter_2 = dist_words_filter_2.most_common(15)
words, frequencies = zip(*common_words_filter_2)
# plot common words
plt.figure(figsize=(8, 3))
plt.bar(words, frequencies)
plt.title('Top 15 Most Common Words')
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()








# remove a few more words and letters by adding them to the list
new_stopwords = ["The", "s", "th", "p", "S"]

filtered = []
for word in tokenized_word_2:
    if word not in new_stopwords:
        filtered.append(word)


%%time
# make one big string out of the list filtered and pass it to the TextBlob() function
text = TextBlob(str(filtered))


tags_list = text.tags
tags_list

# lesson's code does not work again -- error message indicates downloading the below
#running this a second time which is why error message is no longer showing


nltk.download('averaged_perceptron_tagger_eng')


# tags each word with its part of speech i.e. noun, adjective, etc
tags_list = text.tags
tags_list


# create df of info
df_text = pd.DataFrame(tags_list)
df_text.columns = [ 'Words', "Word type"]
df_t=df_text.groupby('Word type').count().reset_index()
top20=df_t.nlargest(20, 'Words')

df_text.head(5)


# create bar plot of each part of speech group
plt.figure(figsize = (10, 5))
with sns.dark_palette("xkcd:blue", 20):
      sns.barplot(x = "Words", y = "Word type",
     saturation = 0.9, data = top20).set_title("20th Century Wikipedia - top 20 word types used")








# looking for singular nouns (NN), plural nouns (NNS), and proper nouns (NNP)
df_nouns = df_text[(df_text['Word type'] == "NN") | (df_text['Word type'] == "NNS") | (df_text['Word type'] == "NNS")]
df_nouns.columns = ["Word", "Occurrences"]
x = df_nouns.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurrences'], ascending=False)
top15_nouns = y.nlargest(15, 'Occurrences') 


# create bar plot
plt.figure(figsize=(15, 5))
sns.set_palette("dark:#5A9_r") 
sns.barplot(x="Word", y="Occurrences", saturation=0.9, data=top15_nouns).set_title("20th Century Wikipedia - most frequently used nouns")








# looking for adjective (JJ), comparative adjective (JJR), and superlative adjective (JJS)
df_adj = df_text[(df_text['Word type'] == "JJ") | (df_text['Word type'] == "JJR") | (df_text['Word type'] == "JJS")]
df_adj.columns = ["Word", "Occurrences"]
x = df_adj.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurrences'], ascending=False)
top15_adj = y.nlargest(15, 'Occurrences') 


# create bar plot
plt.figure(figsize=(15, 5))
sns.set_palette("dark:#5A9_r") 
sns.barplot(x="Word", y="Occurrences", saturation=0.9, data=top15_adj).set_title("20th Century Wikipedia - most frequently used adjectives")








# looking for base form verb (VB), past tense verb (VBD), present participle (VBG), past participle (VBN),
# non-3rd singular present (VBP), 3rd person singular present (VBZ)
verb_tags = ["VB", "VBD", "VBG", "VBN", "VBP", "VBZ"] # list of verb tags
df_verbs = df_text[df_text['Word type'].isin(verb_tags)] # store if word type is in verb_tags
df_verbs.columns = ["Word", "Occurrences"]
x = df_verbs.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurrences'], ascending=False)
top15_verbs = y.nlargest(15, 'Occurrences') 


# create bar plot
plt.figure(figsize=(15, 5))
sns.set_palette("dark:#5A9_r") 
sns.barplot(x="Word", y="Occurrences", saturation=0.9, data=top15_verbs).set_title("20th Century Wikipedia - most frequently used verbs")








countries_df.head(5)


countries_df.drop('Unnamed: 0', axis=1, inplace=True)


countries_df.head()


text


# make text lower case
text_lower = str(text).lower()

# import countries list and make all lower case
countries_df = pd.read_csv("countries_list_20th_century.csv")
countries = countries_df['country_name'].str.lower().tolist()


countries

# there are extra spaces in the countries list, need to remove them


# remove extra spaces from countries
countries = countries_df['country_name'].str.strip().str.lower().tolist()


from collections import Counter
country_counts = Counter()

# country counter
for country in countries:
    count = text_lower.count(country)
    country_counts[country] = count


# put in df
country_freq_df = pd.DataFrame(country_counts.items(), columns=['Country', 'Mentions'])
country_freq_df = country_freq_df.sort_values(by='Mentions', ascending=False)


country_freq_df


country_freq_df.head(20)


country_freq_df['Mentions'].value_counts()


# create bar plot
plt.figure(figsize=(15, 5))
sns.set_palette("dark:#5A9_r") 
sns.barplot(x="Country", y="Mentions", saturation=0.9, data=country_freq_df).set_title("20th Century Wikipedia - country mention counts")


# create new df for only country that have a Mention count > 0
countries_mentioned = country_freq_df[country_freq_df['Mentions'] > 0]


# create bar plot - For only countries mentioned
plt.figure(figsize=(25, 5))
sns.set_palette("dark:#5A9_r") 
sns.barplot(x="Country", y="Mentions", saturation=0.9, data=countries_mentioned).set_title("20th Century Wikipedia - Mentioned Countries")
# Rotate x-axis labels
plt.xticks(rotation=45)






