


import pandas as pd 
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re


nlp = spacy.load("en_core_web_sm")








# Load the wiki text
with open('20th_century_wiki.txt', 'r', errors='ignore') as file: 
   data = file.read().replace( '\n', ' ')

wiki = nlp(data)


from IPython.display import display


# Visualize identified entities
displacy.render([wiki[273:20000]], style="ent", jupyter=True)

# does not work 


df_sentences = []

# Loop through sentences, get entity list for each sentence
for sent in wiki.sents:
    entity_list = [ent.text for ent in sent.ents]
    df_sentences.append({"sentence": sent.text, "entities": entity_list})

df_sentences = pd.DataFrame(df_sentences)


df_sentences.head(10)





# import countries text file
path = 'C:/Users/steve/20th-century'
countries_df = pd.read_csv(os.path.join(path, 'countries_list_20th_century.csv'))


countries_df.head()


countries_df.drop('Unnamed: 0', axis=1, inplace=True)


countries_df['country_name'] = countries_df['country_name'].str.strip().str.replace(r'\s+', ' ', regex=True)


countries_df.head()





# Function to filter out entities not of interest
def filter_entity(ent_list, countries_df):
       return [ent for ent in ent_list
                  if ent in list(countries_df['country_name'])]


df_sentences['country_entities'] = df_sentences['entities'].apply(lambda x: filter_entity(x, countries_df))


# Filter out sentences that donâ€™t have any country entities
df_sentences_filtered = df_sentences[df_sentences['country_entities'].map(len) > 0]

df_sentences_filtered.tail(10)





# Defining relationships with a sliding window
window_size = 5
relationships = []

for i in range(df_sentences_filtered.index[-1]):
    end_i = min(i + window_size, df_sentences_filtered.index[-1])
    
    # Flatten the list of country entities in the window
    country_list = sum(df_sentences_filtered.loc[i:end_i, 'country_entities'].tolist(), [])

    # Remove duplicates that are adjacent
    country_unique = [country_list[j] for j in range(len(country_list))
                      if j == 0 or country_list[j] != country_list[j - 1]]
    
    # If more than one unique country, define edges
    if len(country_unique) > 1:
        for idx, a in enumerate(country_unique[:-1]):
            b = country_unique[idx + 1]
            relationships.append({"source": a, "target": b})


relationship_df = pd.DataFrame(relationships)

relationship_df


# Sort the cases with a- >b and b- >a
relationships_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)
relationships_df.head(5)


relationship_df["value"] = 1
relationship_df = relationship_df.groupby(["source","target"], sort=False, as_index=False).sum()

relationship_df.head(10)





relationship_df.to_csv(os.path)



